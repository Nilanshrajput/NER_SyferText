{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lSTM_colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGNOdEwwLGP84kXo+tWOGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/NER_SyferText/blob/master/lSTM_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBGOlkdKCP9O",
        "colab_type": "code",
        "outputId": "e2296aa1-30be-40ad-b227-5e4468d21b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/synalp/NER.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NER'...\n",
            "remote: Enumerating objects: 3148, done.\u001b[K\n",
            "remote: Total 3148 (delta 0), reused 0 (delta 0), pack-reused 3148\u001b[K\n",
            "Receiving objects: 100% (3148/3148), 281.51 MiB | 30.58 MiB/s, done.\n",
            "Resolving deltas: 100% (2066/2066), done.\n",
            "Checking out files: 100% (189/189), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW7VtQ2yCiPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext.datasets import SequenceTaggingDataset, CoNLL2000Chunking\n",
        "from torchtext.vocab import Vectors, GloVe, CharNGram\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def conll2003_dataset(tag_type, batch_size, root='/content/NER/corpus/CoNLL-2003', \n",
        "                          train_file='eng.train', \n",
        "                          validation_file='eng.testa',\n",
        "                          test_file='eng.testb',\n",
        "                          convert_digits=True):\n",
        "    \"\"\"\n",
        "    conll2003: Conll 2003 (Parser only. You must place the files)\n",
        "    Extract Conll2003 dataset using torchtext. Applies GloVe 6B.200d and Char N-gram\n",
        "    pretrained vectors. Also sets up per word character Field\n",
        "    Parameters:\n",
        "        tag_type: Type of tag to pick as task [pos, chunk, ner]\n",
        "        batch_size: Batch size to return from iterator\n",
        "        root: Dataset root directory\n",
        "        train_file: Train filename\n",
        "        validation_file: Validation filename\n",
        "        test_file: Test filename\n",
        "        convert_digits: If True will convert numbers to single 0's\n",
        "    Returns:\n",
        "        A dict containing:\n",
        "            task: 'conll2003.' + tag_type\n",
        "            iters: (train iter, validation iter, test iter)\n",
        "            vocabs: (Inputs word vocabulary, Inputs character vocabulary, \n",
        "                    Tag vocabulary )\n",
        "    \"\"\"\n",
        "    \n",
        "    # Setup fields with batch dimension first\n",
        "    inputs_word = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\",fix_length=100, batch_first=True, lower=True)\n",
        "\n",
        "    inputs_char_nesting = data.Field(tokenize=list, init_token=\"<bos>\", eos_token=\"<eos>\", \n",
        "                                    batch_first=True)\n",
        "\n",
        "    inputs_char = data.NestedField(inputs_char_nesting, \n",
        "                                    init_token=\"<bos>\", eos_token=\"<eos>\")\n",
        "                        \n",
        "\n",
        "    labels = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\", fix_length=50, batch_first=True)\n",
        "\n",
        "    fields = ([(('inputs_word', 'inputs_char'), (inputs_word, inputs_char))] + \n",
        "                [('labels', labels) if label == tag_type else (None, None) \n",
        "                for label in ['pos', 'chunk', 'ner']])\n",
        "\n",
        "    # Load the data\n",
        "    train, val, test = SequenceTaggingDataset.splits(\n",
        "                                path=root, \n",
        "                                train=train_file, \n",
        "                                validation=validation_file, \n",
        "                                test=test_file,\n",
        "                                separator=' ',\n",
        "                                fields=tuple(fields))\n",
        "\n",
        "\n",
        "    \n",
        "    # Build vocab\n",
        "    inputs_char.build_vocab(train.inputs_char, val.inputs_char, test.inputs_char)\n",
        "    inputs_word.build_vocab(train.inputs_word, val.inputs_word, test.inputs_word, max_size=50000,\n",
        "                        vectors=[GloVe(name='6B', dim='300'), CharNGram()])\n",
        "    \n",
        "    labels.build_vocab(train.labels)\n",
        "  \n",
        "\n",
        "    # Get iterators\n",
        "    train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "                            (train, val, test), batch_size=batch_size, \n",
        "                            device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    train_iter.repeat = False\n",
        "    \n",
        "    return {\n",
        "        'task': 'conll2003.%s'%tag_type,\n",
        "        'iters': (train_iter, val_iter, test_iter), \n",
        "        'vocabs': (inputs_word.vocab, inputs_char.vocab, labels.vocab) \n",
        "        }\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPfLM2mGCwqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e75aeb09-0a0e-4f87-a071-b691ebfd1062"
      },
      "source": [
        "dic = conll2003_dataset('ner', batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.23MB/s]                           \n",
            "100%|█████████▉| 399564/400000 [00:51<00:00, 7591.87it/s]\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz: 0.00B [00:00, ?B/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 8.19k/956M [00:03<119:32:01, 2.22kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 41.0k/956M [00:03<83:58:37, 3.16kB/s] \u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 106k/956M [00:03<58:56:00, 4.50kB/s] \u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 172k/956M [00:04<41:24:12, 6.41kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 369k/956M [00:04<29:01:39, 9.14kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 762k/956M [00:04<20:20:11, 13.0kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 1.55M/956M [00:04<14:14:11, 18.6kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   0%|          | 3.12M/956M [00:04<9:57:19, 26.6kB/s] \u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   1%|          | 6.25M/956M [00:04<6:56:56, 37.9kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   1%|          | 9.31M/956M [00:04<4:51:07, 54.2kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   1%|▏         | 12.2M/956M [00:04<3:23:23, 77.3kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   2%|▏         | 15.3M/956M [00:05<2:22:05, 110kB/s] \u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   2%|▏         | 18.4M/956M [00:05<1:39:19, 157kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   2%|▏         | 21.1M/956M [00:05<1:09:32, 224kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   3%|▎         | 24.2M/956M [00:05<48:42, 319kB/s]  \u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   3%|▎         | 27.2M/956M [00:05<34:11, 453kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   3%|▎         | 30.2M/956M [00:05<24:02, 641kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   3%|▎         | 33.3M/956M [00:05<16:57, 906kB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   4%|▍         | 36.3M/956M [00:05<12:01, 1.27MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   4%|▍         | 39.2M/956M [00:06<08:36, 1.77MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   4%|▍         | 42.3M/956M [00:06<06:11, 2.46MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   5%|▍         | 45.4M/956M [00:06<04:30, 3.37MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   5%|▌         | 48.5M/956M [00:06<03:19, 4.54MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   5%|▌         | 51.6M/956M [00:06<02:30, 6.01MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   6%|▌         | 54.4M/956M [00:06<01:57, 7.65MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   6%|▌         | 57.5M/956M [00:06<01:33, 9.64MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   6%|▋         | 60.6M/956M [00:07<01:17, 11.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   7%|▋         | 63.7M/956M [00:07<01:02, 14.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   7%|▋         | 66.8M/956M [00:07<00:55, 16.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   7%|▋         | 69.7M/956M [00:07<00:53, 16.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   8%|▊         | 72.8M/956M [00:07<00:48, 18.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   8%|▊         | 75.9M/956M [00:07<00:44, 19.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   8%|▊         | 78.8M/956M [00:07<00:43, 20.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   9%|▊         | 81.9M/956M [00:07<00:40, 21.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   9%|▉         | 84.9M/956M [00:08<00:39, 22.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:   9%|▉         | 88.1M/956M [00:08<00:37, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  10%|▉         | 90.8M/956M [00:08<00:38, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  10%|▉         | 93.9M/956M [00:08<00:37, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  10%|█         | 96.9M/956M [00:08<00:36, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  10%|█         | 100M/956M [00:08<00:36, 23.7MB/s] \u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  11%|█         | 103M/956M [00:08<00:36, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  11%|█         | 106M/956M [00:08<00:36, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  11%|█▏        | 109M/956M [00:09<00:36, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  12%|█▏        | 112M/956M [00:09<00:35, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  12%|█▏        | 114M/956M [00:09<00:39, 21.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  12%|█▏        | 117M/956M [00:09<00:37, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  13%|█▎        | 120M/956M [00:09<00:37, 22.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  13%|█▎        | 123M/956M [00:09<00:36, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  13%|█▎        | 125M/956M [00:09<00:39, 20.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  13%|█▎        | 128M/956M [00:09<00:37, 21.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  14%|█▍        | 132M/956M [00:10<00:36, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  14%|█▍        | 135M/956M [00:10<00:35, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  14%|█▍        | 138M/956M [00:10<00:35, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  15%|█▍        | 140M/956M [00:10<00:35, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  15%|█▌        | 144M/956M [00:10<00:34, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  15%|█▌        | 147M/956M [00:10<00:34, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  16%|█▌        | 149M/956M [00:10<00:35, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  16%|█▌        | 152M/956M [00:10<00:35, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  16%|█▋        | 155M/956M [00:11<00:34, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  17%|█▋        | 159M/956M [00:11<00:33, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  17%|█▋        | 162M/956M [00:11<00:33, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  17%|█▋        | 165M/956M [00:11<00:32, 24.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  18%|█▊        | 168M/956M [00:11<00:34, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  18%|█▊        | 171M/956M [00:11<00:33, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  18%|█▊        | 173M/956M [00:11<00:35, 21.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  18%|█▊        | 176M/956M [00:11<00:34, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  19%|█▉        | 179M/956M [00:12<00:33, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  19%|█▉        | 182M/956M [00:12<00:34, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  19%|█▉        | 185M/956M [00:12<00:34, 22.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  20%|█▉        | 188M/956M [00:12<00:34, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  20%|█▉        | 190M/956M [00:12<00:35, 21.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  20%|██        | 194M/956M [00:12<00:33, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  21%|██        | 196M/956M [00:12<00:34, 21.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  21%|██        | 199M/956M [00:13<00:33, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  21%|██        | 202M/956M [00:13<00:32, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  21%|██▏       | 205M/956M [00:13<00:33, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  22%|██▏       | 208M/956M [00:13<00:32, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  22%|██▏       | 211M/956M [00:13<00:32, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  22%|██▏       | 214M/956M [00:13<00:31, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  23%|██▎       | 217M/956M [00:13<00:31, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  23%|██▎       | 220M/956M [00:13<00:30, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  23%|██▎       | 223M/956M [00:14<00:31, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  24%|██▎       | 226M/956M [00:14<00:32, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  24%|██▍       | 229M/956M [00:14<00:31, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  24%|██▍       | 232M/956M [00:14<00:30, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  25%|██▍       | 235M/956M [00:14<00:30, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  25%|██▍       | 238M/956M [00:14<00:29, 24.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  25%|██▌       | 241M/956M [00:14<00:30, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  26%|██▌       | 244M/956M [00:14<00:30, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  26%|██▌       | 247M/956M [00:15<00:29, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  26%|██▌       | 250M/956M [00:15<00:29, 24.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  27%|██▋       | 253M/956M [00:15<00:30, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  27%|██▋       | 256M/956M [00:15<00:30, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  27%|██▋       | 259M/956M [00:15<00:29, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  27%|██▋       | 262M/956M [00:15<00:30, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  28%|██▊       | 265M/956M [00:15<00:29, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  28%|██▊       | 268M/956M [00:15<00:28, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  28%|██▊       | 271M/956M [00:16<00:28, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  29%|██▊       | 275M/956M [00:16<00:28, 24.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  29%|██▉       | 277M/956M [00:16<00:29, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  29%|██▉       | 280M/956M [00:16<00:29, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  30%|██▉       | 283M/956M [00:16<00:28, 23.4MB/s]\u001b[A\n",
            "100%|█████████▉| 399564/400000 [01:10<00:00, 7591.87it/s]\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  30%|███       | 289M/956M [00:16<00:28, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  31%|███       | 292M/956M [00:16<00:28, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  31%|███       | 295M/956M [00:17<00:27, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  31%|███       | 298M/956M [00:17<00:28, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  32%|███▏      | 301M/956M [00:17<00:27, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  32%|███▏      | 304M/956M [00:17<00:29, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  32%|███▏      | 307M/956M [00:17<00:28, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  32%|███▏      | 310M/956M [00:17<00:27, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  33%|███▎      | 313M/956M [00:17<00:26, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  33%|███▎      | 316M/956M [00:17<00:27, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  33%|███▎      | 319M/956M [00:18<00:27, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  34%|███▎      | 322M/956M [00:18<00:26, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  34%|███▍      | 325M/956M [00:18<00:26, 24.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  34%|███▍      | 328M/956M [00:18<00:27, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  35%|███▍      | 331M/956M [00:18<00:26, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  35%|███▍      | 334M/956M [00:18<00:25, 24.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  35%|███▌      | 337M/956M [00:18<00:25, 24.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  36%|███▌      | 341M/956M [00:19<00:25, 24.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  36%|███▌      | 343M/956M [00:19<00:26, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  36%|███▋      | 347M/956M [00:19<00:25, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  37%|███▋      | 350M/956M [00:19<00:25, 24.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  37%|███▋      | 353M/956M [00:19<00:25, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  37%|███▋      | 355M/956M [00:19<00:26, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  37%|███▋      | 358M/956M [00:19<00:25, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  38%|███▊      | 361M/956M [00:19<00:25, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  38%|███▊      | 364M/956M [00:20<00:25, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  38%|███▊      | 367M/956M [00:20<00:25, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  39%|███▉      | 370M/956M [00:20<00:24, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  39%|███▉      | 373M/956M [00:20<00:26, 22.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  39%|███▉      | 376M/956M [00:20<00:25, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  40%|███▉      | 379M/956M [00:20<00:25, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  40%|███▉      | 382M/956M [00:20<00:25, 22.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  40%|████      | 385M/956M [00:20<00:24, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  41%|████      | 388M/956M [00:21<00:24, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  41%|████      | 391M/956M [00:21<00:24, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  41%|████      | 394M/956M [00:21<00:24, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  41%|████▏     | 397M/956M [00:21<00:24, 22.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  42%|████▏     | 399M/956M [00:21<00:27, 20.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  42%|████▏     | 402M/956M [00:21<00:25, 21.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  42%|████▏     | 404M/956M [00:21<00:26, 20.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  43%|████▎     | 407M/956M [00:21<00:25, 21.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  43%|████▎     | 410M/956M [00:22<00:25, 21.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  43%|████▎     | 412M/956M [00:22<00:25, 21.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  43%|████▎     | 415M/956M [00:22<00:24, 21.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  44%|████▍     | 419M/956M [00:22<00:23, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  44%|████▍     | 421M/956M [00:22<00:26, 20.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  44%|████▍     | 424M/956M [00:22<00:24, 21.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  45%|████▍     | 427M/956M [00:22<00:23, 22.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  45%|████▍     | 430M/956M [00:22<00:24, 21.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  45%|████▌     | 433M/956M [00:23<00:23, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  46%|████▌     | 436M/956M [00:23<00:22, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  46%|████▌     | 439M/956M [00:23<00:21, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  46%|████▌     | 442M/956M [00:23<00:21, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  47%|████▋     | 445M/956M [00:23<00:21, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  47%|████▋     | 448M/956M [00:23<00:22, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  47%|████▋     | 451M/956M [00:23<00:21, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  48%|████▊     | 454M/956M [00:23<00:21, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  48%|████▊     | 457M/956M [00:24<00:21, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  48%|████▊     | 460M/956M [00:24<00:21, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  48%|████▊     | 463M/956M [00:24<00:21, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  49%|████▉     | 466M/956M [00:24<00:20, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  49%|████▉     | 469M/956M [00:24<00:20, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  49%|████▉     | 472M/956M [00:24<00:21, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  50%|████▉     | 475M/956M [00:24<00:20, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  50%|████▉     | 478M/956M [00:25<00:20, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  50%|█████     | 480M/956M [00:25<00:20, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  51%|█████     | 484M/956M [00:25<00:20, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  51%|█████     | 486M/956M [00:25<00:20, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  51%|█████     | 489M/956M [00:25<00:20, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  52%|█████▏    | 492M/956M [00:25<00:20, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  52%|█████▏    | 495M/956M [00:25<00:20, 22.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  52%|█████▏    | 498M/956M [00:25<00:20, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  52%|█████▏    | 500M/956M [00:26<00:21, 21.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  53%|█████▎    | 503M/956M [00:26<00:20, 22.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  53%|█████▎    | 506M/956M [00:26<00:19, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  53%|█████▎    | 509M/956M [00:26<00:19, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  54%|█████▎    | 512M/956M [00:26<00:19, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  54%|█████▍    | 515M/956M [00:26<00:18, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  54%|█████▍    | 518M/956M [00:26<00:18, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  55%|█████▍    | 521M/956M [00:26<00:18, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  55%|█████▍    | 524M/956M [00:27<00:18, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  55%|█████▌    | 527M/956M [00:27<00:18, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  55%|█████▌    | 530M/956M [00:27<00:18, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  56%|█████▌    | 533M/956M [00:27<00:17, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  56%|█████▌    | 536M/956M [00:27<00:17, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  56%|█████▋    | 538M/956M [00:27<00:20, 20.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  57%|█████▋    | 541M/956M [00:27<00:19, 21.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  57%|█████▋    | 545M/956M [00:27<00:18, 22.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  57%|█████▋    | 547M/956M [00:28<00:18, 21.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  58%|█████▊    | 550M/956M [00:28<00:18, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  58%|█████▊    | 554M/956M [00:28<00:17, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  58%|█████▊    | 556M/956M [00:28<00:17, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  59%|█████▊    | 560M/956M [00:28<00:17, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  59%|█████▉    | 563M/956M [00:28<00:16, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  59%|█████▉    | 566M/956M [00:28<00:16, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  59%|█████▉    | 568M/956M [00:28<00:16, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  60%|█████▉    | 572M/956M [00:29<00:16, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  60%|██████    | 574M/956M [00:29<00:16, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  60%|██████    | 577M/956M [00:29<00:17, 22.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  61%|██████    | 580M/956M [00:29<00:16, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  61%|██████    | 583M/956M [00:29<00:16, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  61%|██████▏   | 586M/956M [00:29<00:16, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  62%|██████▏   | 589M/956M [00:29<00:16, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  62%|██████▏   | 592M/956M [00:29<00:16, 22.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  62%|██████▏   | 595M/956M [00:30<00:15, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  63%|██████▎   | 598M/956M [00:30<00:15, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  63%|██████▎   | 600M/956M [00:30<00:15, 22.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  63%|██████▎   | 604M/956M [00:30<00:15, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  63%|██████▎   | 607M/956M [00:30<00:14, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  64%|██████▍   | 609M/956M [00:30<00:15, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  64%|██████▍   | 612M/956M [00:30<00:15, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  64%|██████▍   | 615M/956M [00:31<00:14, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  65%|██████▍   | 618M/956M [00:31<00:14, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  65%|██████▍   | 621M/956M [00:31<00:14, 22.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  65%|██████▌   | 624M/956M [00:31<00:14, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  66%|██████▌   | 627M/956M [00:31<00:14, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  66%|██████▌   | 630M/956M [00:31<00:14, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  66%|██████▌   | 633M/956M [00:31<00:14, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  67%|██████▋   | 636M/956M [00:31<00:13, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  67%|██████▋   | 639M/956M [00:32<00:13, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  67%|██████▋   | 642M/956M [00:32<00:13, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  67%|██████▋   | 645M/956M [00:32<00:13, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  68%|██████▊   | 648M/956M [00:32<00:13, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  68%|██████▊   | 651M/956M [00:32<00:13, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  68%|██████▊   | 654M/956M [00:32<00:12, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  69%|██████▊   | 656M/956M [00:32<00:13, 22.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  69%|██████▉   | 659M/956M [00:32<00:12, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  69%|██████▉   | 663M/956M [00:33<00:12, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  70%|██████▉   | 666M/956M [00:33<00:12, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  70%|██████▉   | 668M/956M [00:33<00:14, 20.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  70%|███████   | 671M/956M [00:33<00:13, 21.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  70%|███████   | 674M/956M [00:33<00:13, 21.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  71%|███████   | 677M/956M [00:33<00:12, 22.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  71%|███████   | 679M/956M [00:33<00:13, 20.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  71%|███████▏  | 682M/956M [00:33<00:12, 21.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  72%|███████▏  | 685M/956M [00:34<00:12, 21.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  72%|███████▏  | 688M/956M [00:34<00:12, 22.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  72%|███████▏  | 691M/956M [00:34<00:11, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  73%|███████▎  | 694M/956M [00:34<00:11, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  73%|███████▎  | 696M/956M [00:34<00:11, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  73%|███████▎  | 699M/956M [00:34<00:11, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  74%|███████▎  | 703M/956M [00:34<00:10, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  74%|███████▍  | 706M/956M [00:34<00:10, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  74%|███████▍  | 709M/956M [00:35<00:10, 24.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  74%|███████▍  | 712M/956M [00:35<00:10, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  75%|███████▍  | 715M/956M [00:35<00:10, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  75%|███████▌  | 718M/956M [00:35<00:10, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  75%|███████▌  | 721M/956M [00:35<00:09, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  76%|███████▌  | 724M/956M [00:35<00:10, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  76%|███████▌  | 726M/956M [00:35<00:11, 20.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  76%|███████▋  | 729M/956M [00:36<00:10, 21.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  76%|███████▋  | 731M/956M [00:36<00:12, 17.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  77%|███████▋  | 734M/956M [00:36<00:11, 19.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  77%|███████▋  | 736M/956M [00:36<00:10, 20.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  77%|███████▋  | 739M/956M [00:36<00:10, 20.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  78%|███████▊  | 742M/956M [00:36<00:10, 19.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  78%|███████▊  | 744M/956M [00:36<00:10, 20.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  78%|███████▊  | 747M/956M [00:36<00:10, 19.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  78%|███████▊  | 750M/956M [00:37<00:09, 20.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  79%|███████▉  | 753M/956M [00:37<00:09, 21.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  79%|███████▉  | 756M/956M [00:37<00:09, 21.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  79%|███████▉  | 759M/956M [00:37<00:08, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  80%|███████▉  | 762M/956M [00:37<00:08, 22.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  80%|████████  | 765M/956M [00:37<00:08, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  80%|████████  | 768M/956M [00:37<00:08, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  81%|████████  | 770M/956M [00:37<00:08, 20.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  81%|████████  | 773M/956M [00:38<00:08, 21.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  81%|████████  | 776M/956M [00:38<00:08, 21.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  82%|████████▏ | 779M/956M [00:38<00:07, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  82%|████████▏ | 782M/956M [00:38<00:07, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  82%|████████▏ | 785M/956M [00:38<00:07, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  82%|████████▏ | 788M/956M [00:38<00:07, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  83%|████████▎ | 791M/956M [00:38<00:07, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  83%|████████▎ | 794M/956M [00:38<00:07, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  83%|████████▎ | 796M/956M [00:39<00:07, 22.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  84%|████████▎ | 800M/956M [00:39<00:06, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  84%|████████▍ | 803M/956M [00:39<00:06, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  84%|████████▍ | 806M/956M [00:39<00:06, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  85%|████████▍ | 809M/956M [00:39<00:06, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  85%|████████▍ | 812M/956M [00:39<00:06, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  85%|████████▌ | 815M/956M [00:39<00:05, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  86%|████████▌ | 818M/956M [00:39<00:06, 22.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  86%|████████▌ | 821M/956M [00:40<00:05, 23.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  86%|████████▌ | 824M/956M [00:40<00:05, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  86%|████████▋ | 826M/956M [00:40<00:05, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  87%|████████▋ | 830M/956M [00:40<00:05, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  87%|████████▋ | 833M/956M [00:40<00:05, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  87%|████████▋ | 836M/956M [00:40<00:05, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  88%|████████▊ | 839M/956M [00:40<00:05, 22.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  88%|████████▊ | 842M/956M [00:40<00:04, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  88%|████████▊ | 845M/956M [00:41<00:04, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  89%|████████▊ | 848M/956M [00:41<00:04, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  89%|████████▉ | 851M/956M [00:41<00:04, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  89%|████████▉ | 854M/956M [00:41<00:04, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  90%|████████▉ | 857M/956M [00:41<00:04, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  90%|████████▉ | 860M/956M [00:41<00:04, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  90%|█████████ | 863M/956M [00:41<00:04, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  91%|█████████ | 865M/956M [00:42<00:03, 22.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  91%|█████████ | 869M/956M [00:42<00:03, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  91%|█████████ | 872M/956M [00:42<00:03, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  92%|█████████▏| 875M/956M [00:42<00:03, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  92%|█████████▏| 878M/956M [00:42<00:03, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  92%|█████████▏| 881M/956M [00:42<00:03, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  92%|█████████▏| 884M/956M [00:42<00:03, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  93%|█████████▎| 887M/956M [00:42<00:02, 23.1MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  93%|█████████▎| 890M/956M [00:43<00:02, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  93%|█████████▎| 893M/956M [00:43<00:02, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  94%|█████████▍| 896M/956M [00:43<00:02, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  94%|█████████▍| 899M/956M [00:43<00:02, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  94%|█████████▍| 902M/956M [00:43<00:02, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  95%|█████████▍| 905M/956M [00:43<00:02, 23.8MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  95%|█████████▌| 908M/956M [00:43<00:01, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  95%|█████████▌| 911M/956M [00:43<00:01, 23.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  96%|█████████▌| 914M/956M [00:44<00:01, 23.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  96%|█████████▌| 917M/956M [00:44<00:01, 23.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  96%|█████████▋| 920M/956M [00:44<00:01, 23.7MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  97%|█████████▋| 923M/956M [00:44<00:01, 24.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  97%|█████████▋| 926M/956M [00:44<00:01, 24.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  97%|█████████▋| 929M/956M [00:44<00:01, 24.3MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  98%|█████████▊| 932M/956M [00:44<00:00, 24.4MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  98%|█████████▊| 935M/956M [00:44<00:00, 24.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  98%|█████████▊| 938M/956M [00:45<00:00, 23.2MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  99%|█████████▊| 941M/956M [00:45<00:00, 23.6MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  99%|█████████▉| 945M/956M [00:45<00:00, 23.9MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz:  99%|█████████▉| 948M/956M [00:45<00:00, 24.0MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz: 100%|█████████▉| 951M/956M [00:45<00:00, 24.5MB/s]\u001b[A\n",
            ".vector_cache/jmt_pre-trained_embeddings.tar.gz: 956MB [00:45, 20.9MB/s]                           \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PqRap7oC-1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while 1:\n",
        "  continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0aXkbnHHDdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c = dic['iters']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQwZu28UUEWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab,_,_ = dic['vocabs']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZLdZPK7UPXA",
        "colab_type": "code",
        "outputId": "74a8b59c-3b34-463c-dae4-5c5717a15197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vsz = len(vocab)\n",
        "print(vsz)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbTwNX2TPFUq",
        "colab_type": "code",
        "outputId": "195211bb-22a1-4d6e-d916-d378577a7d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "t\n",
        "for t in enumerate(a):\n",
        "  print(t)\n",
        "  print(len(t))\n",
        "  t=t[1]\n",
        "  print(t[1])\n",
        "  "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, \n",
            "[torchtext.data.batch.Batch of size 1]\n",
            "\t[.labels]:[torch.LongTensor of size 1x50]\n",
            "\t[.inputs_word]:[torch.LongTensor of size 1x100]\n",
            "\t[.inputs_char]:[torch.LongTensor of size 1x9x12])\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a23a513da4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Batch' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpVAP3RgPGlp",
        "colab_type": "code",
        "outputId": "8f050577-9ee0-4ef4-d886-aca165f1317a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "t"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 1]\n",
              "\t[.labels]:[torch.LongTensor of size 1x50]\n",
              "\t[.inputs_word]:[torch.LongTensor of size 1x100]\n",
              "\t[.inputs_char]:[torch.LongTensor of size 1x9x12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XHNN88EQooN",
        "colab_type": "code",
        "outputId": "327cce9b-caad-44b6-bf48-8a669764a428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.inputs_word.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5H9FyaZQw01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM_Tagger(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(LSTM_Tagger, self).__init__()\n",
        "\n",
        "        #maps each token to an embedding_dim vector\n",
        "        self.embedding = nn.Embedding(params['vocab_size'], params['embedding_dim'])\n",
        "\n",
        "        #the LSTM takens embedded sentence\n",
        "        self.lstm = nn.LSTM(params['embedding_dim'], params['lstm_hidden_dim'], batch_first=True)\n",
        "\n",
        "        #fc layer transforms the output to give the final output layer\n",
        "        self.fc = nn.Linear(params['lstm_hidden_dim'], params['num_tags'])\n",
        "\n",
        "    def forward(self, s):\n",
        "        #apply the embedding layer that maps each token to its embedding\n",
        "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
        "\n",
        "        #run the LSTM along the sentences of length batch_max_len\n",
        "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim                \n",
        "\n",
        "        #reshape the Variable so that each row contains one token\n",
        "        s = s.view(-1, s.shape[2])  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
        "\n",
        "        #apply the fully connected layer and obtain the output for each token\n",
        "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
        "\n",
        "        return F.log_softmax(s, dim=1)   # dim: batch_size*batch_max_len x num_tags\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le-wpgUeSwo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = nn.Embedding(vsz, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grom9WkTUljy",
        "colab_type": "code",
        "outputId": "d4bc5f73-9830-4454-e402-be44ac40a2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(embedding(t.inputs_word).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 34, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFytRdKrUwHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, labels):\n",
        "    #reshape labels to give a flat vector of length batch_size*seq_len\n",
        "    labels = labels.view(-1)  \n",
        "\n",
        "    #mask out 'PAD' tokens\n",
        "    mask = (labels >= 0).float()\n",
        "\n",
        "    #the number of tokens is the sum of elements in mask\n",
        "    num_tokens = int(torch.sum(mask).data[0])\n",
        "\n",
        "    #pick the values corresponding to labels and multiply by mask\n",
        "    outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
        "\n",
        "    #cross entropy loss for all non 'PAD' tokens\n",
        "    return -torch.sum(outputs)/num_tokens\n",
        "\n",
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "    \n",
        "def train_model(model, train_iter, epoch):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.cuda()\n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(train_iter):\n",
        "        text = batch.inputs_word\n",
        "        print(text)\n",
        "        print(text.shape)\n",
        "        print(text[1])\n",
        "        break\n",
        "        target = batch.labels\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        if torch.cuda.is_available():\n",
        "            text = text.cuda()\n",
        "            target = target.cuda()\n",
        "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\n",
        "            continue\n",
        "        optim.zero_grad()\n",
        "        prediction = model(text)\n",
        "        loss = loss_fn(prediction, target)\n",
        "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * num_corrects/len(batch)\n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optim.step()\n",
        "        steps += 1\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        total_epoch_acc += acc.item()\n",
        "        \n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
        "\n",
        "def eval_model(model, val_iter):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_iter):\n",
        "            text = batch.text[0]\n",
        "            if (text.size()[0] is not 32):\n",
        "                continue\n",
        "            target = batch.label\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            if torch.cuda.is_available():\n",
        "                text = text.cuda()\n",
        "                target = target.cuda()\n",
        "            prediction = model(text)\n",
        "            loss = loss_fn(prediction, target)\n",
        "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(batch)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)\n",
        "\t\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USEclqAO6Xo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "19bad5ad-5f8c-4d98-a0ca-b180dfe9b8a2"
      },
      "source": [
        "learning_rate = 2e-5\n",
        "batch_size = 64\n",
        "\n",
        "lstm_hidden_dim = 256\n",
        "num_tags = 17\n",
        "embedding_length = 300\n",
        "train_iter,valid_iter,test_iter = dic['iters']\n",
        "vsz = len(dic['vocabs'])\n",
        "params={'vocab_size':vsz, 'embedding_dim':embedding_length,'lstm_hidden_dim': lstm_hidden_dim, 'num_tags':num_tags}\n",
        "model = LSTM_Tagger(params)\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train_model(model, train_iter, epoch)\n",
        "    val_loss, val_acc = eval_model(model, valid_iter)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
        "    \n",
        "test_loss, test_acc = eval_model(model, test_iter)\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6f8f2a657479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0membedding_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocabs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'vocab_size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_dim'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0membedding_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lstm_hidden_dim'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlstm_hidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_tags'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_tags\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dic' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrW7tPOc7jLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "bb47b180-57af-4bb3-fc05-07ce4a3ca3cb"
      },
      "source": [
        "params={'vocab_size':5, 'embedding_dim':5}\n",
        "params.vocab_size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ed358cc1f665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'vocab_size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_dim'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'vocab_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78I3kUZd7oiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}