{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lSTM_colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPA8gkiqOcsYctAGuj7fUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/NER_SyferText/blob/master/lSTM_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBGOlkdKCP9O",
        "colab_type": "code",
        "outputId": "e2296aa1-30be-40ad-b227-5e4468d21b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/synalp/NER.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NER'...\n",
            "remote: Enumerating objects: 3148, done.\u001b[K\n",
            "remote: Total 3148 (delta 0), reused 0 (delta 0), pack-reused 3148\u001b[K\n",
            "Receiving objects: 100% (3148/3148), 281.51 MiB | 30.58 MiB/s, done.\n",
            "Resolving deltas: 100% (2066/2066), done.\n",
            "Checking out files: 100% (189/189), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW7VtQ2yCiPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext.datasets import SequenceTaggingDataset, CoNLL2000Chunking\n",
        "from torchtext.vocab import Vectors, GloVe, CharNGram\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def conll2003_dataset(tag_type, batch_size, root='/content/NER/corpus/CoNLL-2003', \n",
        "                          train_file='eng.train', \n",
        "                          validation_file='eng.testa',\n",
        "                          test_file='eng.testb',\n",
        "                          convert_digits=True):\n",
        "    \"\"\"\n",
        "    conll2003: Conll 2003 (Parser only. You must place the files)\n",
        "    Extract Conll2003 dataset using torchtext. Applies GloVe 6B.200d and Char N-gram\n",
        "    pretrained vectors. Also sets up per word character Field\n",
        "    Parameters:\n",
        "        tag_type: Type of tag to pick as task [pos, chunk, ner]\n",
        "        batch_size: Batch size to return from iterator\n",
        "        root: Dataset root directory\n",
        "        train_file: Train filename\n",
        "        validation_file: Validation filename\n",
        "        test_file: Test filename\n",
        "        convert_digits: If True will convert numbers to single 0's\n",
        "    Returns:\n",
        "        A dict containing:\n",
        "            task: 'conll2003.' + tag_type\n",
        "            iters: (train iter, validation iter, test iter)\n",
        "            vocabs: (Inputs word vocabulary, Inputs character vocabulary, \n",
        "                    Tag vocabulary )\n",
        "    \"\"\"\n",
        "    \n",
        "    # Setup fields with batch dimension first\n",
        "    inputs_word = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\",fix_length=100, batch_first=True, lower=True)\n",
        "\n",
        "    inputs_char_nesting = data.Field(tokenize=list, init_token=\"<bos>\", eos_token=\"<eos>\", \n",
        "                                    batch_first=True)\n",
        "\n",
        "    inputs_char = data.NestedField(inputs_char_nesting, \n",
        "                                    init_token=\"<bos>\", eos_token=\"<eos>\")\n",
        "                        \n",
        "\n",
        "    labels = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\", fix_length=50, batch_first=True)\n",
        "\n",
        "    fields = ([(('inputs_word', 'inputs_char'), (inputs_word, inputs_char))] + \n",
        "                [('labels', labels) if label == tag_type else (None, None) \n",
        "                for label in ['pos', 'chunk', 'ner']])\n",
        "\n",
        "    # Load the data\n",
        "    train, val, test = SequenceTaggingDataset.splits(\n",
        "                                path=root, \n",
        "                                train=train_file, \n",
        "                                validation=validation_file, \n",
        "                                test=test_file,\n",
        "                                separator=' ',\n",
        "                                fields=tuple(fields))\n",
        "\n",
        "\n",
        "    \n",
        "    # Build vocab\n",
        "    inputs_char.build_vocab(train.inputs_char, val.inputs_char, test.inputs_char)\n",
        "    inputs_word.build_vocab(train.inputs_word, val.inputs_word, test.inputs_word, max_size=50000,\n",
        "                        vectors=[GloVe(name='6B', dim='300'), CharNGram()])\n",
        "    \n",
        "    labels.build_vocab(train.labels)\n",
        "  \n",
        "\n",
        "    # Get iterators\n",
        "    train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "                            (train, val, test), batch_size=batch_size, \n",
        "                            device=torch.device(\"cpu\"))\n",
        "    train_iter.repeat = False\n",
        "    \n",
        "    return {\n",
        "        'task': 'conll2003.%s'%tag_type,\n",
        "        'iters': (train_iter, val_iter, test_iter), \n",
        "        'vocabs': (inputs_word.vocab, inputs_char.vocab, labels.vocab) \n",
        "        }\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPfLM2mGCwqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = conll2003_dataset('ner', batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PqRap7oC-1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while 1:\n",
        "  continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0aXkbnHHDdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c = dic['iters']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQwZu28UUEWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab,_,_ = dic['vocabs']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZLdZPK7UPXA",
        "colab_type": "code",
        "outputId": "74a8b59c-3b34-463c-dae4-5c5717a15197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vsz = len(vocab)\n",
        "print(vsz)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbTwNX2TPFUq",
        "colab_type": "code",
        "outputId": "195211bb-22a1-4d6e-d916-d378577a7d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "t\n",
        "for t in enumerate(a):\n",
        "  print(t)\n",
        "  print(len(t))\n",
        "  t=t[1]\n",
        "  print(t[1])\n",
        "  "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, \n",
            "[torchtext.data.batch.Batch of size 1]\n",
            "\t[.labels]:[torch.LongTensor of size 1x50]\n",
            "\t[.inputs_word]:[torch.LongTensor of size 1x100]\n",
            "\t[.inputs_char]:[torch.LongTensor of size 1x9x12])\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a23a513da4b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Batch' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpVAP3RgPGlp",
        "colab_type": "code",
        "outputId": "8f050577-9ee0-4ef4-d886-aca165f1317a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "t"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 1]\n",
              "\t[.labels]:[torch.LongTensor of size 1x50]\n",
              "\t[.inputs_word]:[torch.LongTensor of size 1x100]\n",
              "\t[.inputs_char]:[torch.LongTensor of size 1x9x12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XHNN88EQooN",
        "colab_type": "code",
        "outputId": "327cce9b-caad-44b6-bf48-8a669764a428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.inputs_word.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5H9FyaZQw01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM_Tagger(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(LSTM_Tagger, self).__init__()\n",
        "\n",
        "        #maps each token to an embedding_dim vector\n",
        "        self.embedding = nn.Embedding(params['vocab_size'], params['embedding_dim'])\n",
        "\n",
        "        #the LSTM takens embedded sentence\n",
        "        self.lstm = nn.LSTM(params['embedding_dim'], params['lstm_hidden_dim'], batch_first=True)\n",
        "\n",
        "        #fc layer transforms the output to give the final output layer\n",
        "        self.fc = nn.Linear(params['lstm_hidden_dim'], params['num_tags'])\n",
        "\n",
        "    def forward(self, s):\n",
        "        #apply the embedding layer that maps each token to its embedding\n",
        "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
        "\n",
        "        #run the LSTM along the sentences of length batch_max_len\n",
        "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim                \n",
        "\n",
        "        #reshape the Variable so that each row contains one token\n",
        "        s = s.view(-1, s.shape[2])  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
        "\n",
        "        #apply the fully connected layer and obtain the output for each token\n",
        "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
        "\n",
        "        return F.log_softmax(s, dim=1)   # dim: batch_size*batch_max_len x num_tags\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le-wpgUeSwo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = nn.Embedding(vsz, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grom9WkTUljy",
        "colab_type": "code",
        "outputId": "d4bc5f73-9830-4454-e402-be44ac40a2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(embedding(t.inputs_word).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 34, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFytRdKrUwHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "def loss_fn(outputs, labels):\n",
        "    #reshape labels to give a flat vector of length batch_size*seq_len\n",
        "    labels = labels.view(-1)  \n",
        "\n",
        "    #mask out 'PAD' tokens\n",
        "    mask = (labels >= 0).float()\n",
        "\n",
        "    #the number of tokens is the sum of elements in mask\n",
        "    num_tokens = int(torch.sum(mask).data[0])\n",
        "\n",
        "    #pick the values corresponding to labels and multiply by mask\n",
        "    outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
        "\n",
        "    #cross entropy loss for all non 'PAD' tokens\n",
        "    return -torch.sum(outputs)/num_tokens\n",
        "\n",
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "    \n",
        "def train_model(model, train_iter, epoch):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.to(device)\n",
        "    \n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(train_iter):\n",
        "        text = batch.inputs_word\n",
        "       \n",
        "        target = batch.labels\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        if torch.cuda.is_available():\n",
        "            text = text.to(device)\n",
        "            target = target.to(device)\n",
        "        if (text.size()[0] is not 64):# One of the batch returned by BucketIterator has length different than 32.\n",
        "            continue\n",
        "        optim.zero_grad()\n",
        "        prediction = model(text)\n",
        "        loss = loss_fn(prediction, target)\n",
        "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * num_corrects/len(batch)\n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optim.step()\n",
        "        steps += 1\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        total_epoch_acc += acc.item()\n",
        "        \n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n",
        "\n",
        "def eval_model(model, val_iter):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_iter):\n",
        "            text = batch.inputs_word\n",
        "            if (text.size()[0] is not 64):\n",
        "                continue\n",
        "            target = batch.labels\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            if torch.cuda.is_available():\n",
        "                text = text.cuda()\n",
        "                target = target.cuda()\n",
        "            prediction = model(text)\n",
        "            loss = loss_fn(prediction, target)\n",
        "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(batch)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter)\n",
        "\t\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USEclqAO6Xo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "9d12ed45-40a3-4c03-9a56-4b122142024a"
      },
      "source": [
        "learning_rate = 2e-5\n",
        "batch_size = 64\n",
        "\n",
        "lstm_hidden_dim = 256\n",
        "num_tags = 17\n",
        "embedding_length = 300\n",
        "train_iter,valid_iter,test_iter = dic['iters']\n",
        "vocab,_,_ = dic['vocabs']\n",
        "vsz = len(vocab)\n",
        "params={'vocab_size':vsz, 'embedding_dim':embedding_length,'lstm_hidden_dim': lstm_hidden_dim, 'num_tags':num_tags}\n",
        "model = LSTM_Tagger(params)\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train_model(model, train_iter, epoch)\n",
        "    val_loss, val_acc = eval_model(model, valid_iter)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
        "    \n",
        "test_loss, test_acc = eval_model(model, test_iter)\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-97783bb811bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_Tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ece4d0786894>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_iter, epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mnum_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-0028b514c43b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#reshape the Variable so that each row contains one token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dim: batch_size*batch_max_len x lstm_hidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#apply the fully connected layer and obtain the output for each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrW7tPOc7jLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca2a1f0b-b922-40dc-896e-938e8d4805a6"
      },
      "source": [
        "vsz = len(dic['vocabs'])\n",
        "vsz"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78I3kUZd7oiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}